"""
ğŸš€ ê³ ì„±ëŠ¥ ë¶„ì‚° ìºì‹œ ì‹œìŠ¤í…œ - Redis ê¸°ë°˜ ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ ê·¹ëŒ€í™”
"""

import json
import hashlib
import threading
import time
from typing import Optional, Dict, Any, Tuple, List, Union
from datetime import datetime, timedelta
from dataclasses import dataclass
import asyncio
import os
from contextlib import asynccontextmanager

# Redis ì—°ê²°ì„ ìœ„í•œ import (ì„ íƒì )
try:
    import redis.asyncio as redis
    import redis.exceptions as redis_exceptions
    REDIS_AVAILABLE = True
except ImportError:
    redis = None
    redis_exceptions = None
    REDIS_AVAILABLE = False

from scripts.response_cache import ThreadSafeResponseCache

@dataclass
class CacheConfig:
    """ìºì‹œ ì„¤ì • í´ë˜ìŠ¤"""
    # Redis ì„¤ì •
    redis_url: str = "redis://localhost:6379"
    redis_password: Optional[str] = None
    redis_db: int = 0
    redis_timeout: int = 5
    
    # ìºì‹œ ê³„ì¸µ ì„¤ì •
    l1_max_size: int = 100  # ë¡œì»¬ ìºì‹œ í¬ê¸°
    l1_ttl_hours: int = 1   # ë¡œì»¬ ìºì‹œ TTL
    l2_ttl_hours: int = 24  # Redis ìºì‹œ TTL
    
    # ì„±ëŠ¥ ì„¤ì •
    compression_enabled: bool = True
    batch_size: int = 50
    connection_pool_size: int = 10

class DistributedCacheManager:
    """
    ğŸš€ 2ë‹¨ê³„ ë¶„ì‚° ìºì‹œ ì‹œìŠ¤í…œ
    
    L1: ë¡œì»¬ ë©”ëª¨ë¦¬ ìºì‹œ (ThreadSafeResponseCache)
    L2: Redis ë¶„ì‚° ìºì‹œ
    """
    
    def __init__(self, config: Optional[CacheConfig] = None):
        self.config = config or CacheConfig()
        
        # L1 ìºì‹œ (ë¡œì»¬ ë©”ëª¨ë¦¬)
        self.l1_cache = ThreadSafeResponseCache(
            max_size=self.config.l1_max_size,
            ttl_hours=self.config.l1_ttl_hours
        )
        
        # L2 ìºì‹œ (Redis) - ë¹„ë™ê¸° ì—°ê²°
        self.redis_pool: Optional[redis.ConnectionPool] = None
        self.redis_client: Optional[redis.Redis] = None
        self._redis_lock = threading.RLock()
        self._initialized = False
        
        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'l1_hits': 0,
            'l2_hits': 0,
            'misses': 0,
            'errors': 0,
            'total_requests': 0,
            'avg_response_time': 0.0
        }
        
        # Redis ì—°ê²° ìƒíƒœ
        self.redis_healthy = False
        self.last_health_check = 0
        self.health_check_interval = 30  # 30ì´ˆë§ˆë‹¤ í—¬ìŠ¤ ì²´í¬
    
    async def initialize(self) -> bool:
        """
        Redis ì—°ê²°ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        if not REDIS_AVAILABLE:
            print("âš ï¸ Redisê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ë¡œì»¬ ìºì‹œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self._initialized = True
            return True
        
        try:
            # Redis ì—°ê²° í’€ ìƒì„±
            self.redis_pool = redis.ConnectionPool.from_url(
                self.config.redis_url,
                password=self.config.redis_password,
                db=self.config.redis_db,
                max_connections=self.config.connection_pool_size,
                socket_connect_timeout=self.config.redis_timeout,
                socket_timeout=self.config.redis_timeout,
                retry_on_timeout=True,
                health_check_interval=30
            )
            
            self.redis_client = redis.Redis(connection_pool=self.redis_pool)
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            await self.redis_client.ping()
            self.redis_healthy = True
            print("âœ… Redis ì—°ê²° ì„±ê³µ")
            
        except Exception as e:
            print(f"âŒ Redis ì—°ê²° ì‹¤íŒ¨: {str(e)}")
            print("âš ï¸ ë¡œì»¬ ìºì‹œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.redis_healthy = False
        
        self._initialized = True
        return True
    
    async def _check_redis_health(self) -> bool:
        """Redis ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
        current_time = time.time()
        
        # ì¼ì • ê°„ê²©ìœ¼ë¡œë§Œ í—¬ìŠ¤ ì²´í¬ ìˆ˜í–‰
        if current_time - self.last_health_check < self.health_check_interval:
            return self.redis_healthy
        
        self.last_health_check = current_time
        
        if not self.redis_client:
            self.redis_healthy = False
            return False
        
        try:
            await asyncio.wait_for(self.redis_client.ping(), timeout=2.0)
            if not self.redis_healthy:
                print("âœ… Redis ì—°ê²° ë³µêµ¬ë¨")
            self.redis_healthy = True
        except Exception as e:
            if self.redis_healthy:
                print(f"âŒ Redis ì—°ê²° ëŠì–´ì§: {str(e)}")
            self.redis_healthy = False
        
        return self.redis_healthy
    
    def _generate_cache_key(self, question: str, category: Optional[str] = None, 
                          section: Optional[str] = None) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = {
            'question': question.lower().strip(),
            'category': category,
            'section': section
        }
        key_string = json.dumps(key_data, sort_keys=True, ensure_ascii=False)
        return f"chat_cache:{hashlib.sha256(key_string.encode()).hexdigest()[:16]}"
    
    def _compress_data(self, data: str) -> bytes:
        """ë°ì´í„° ì••ì¶• (ì„ íƒì )"""
        if not self.config.compression_enabled:
            return data.encode('utf-8')
        
        try:
            import zlib
            return zlib.compress(data.encode('utf-8'))
        except ImportError:
            return data.encode('utf-8')
    
    def _decompress_data(self, data: bytes) -> str:
        """ë°ì´í„° ì••ì¶• í•´ì œ"""
        if not self.config.compression_enabled:
            return data.decode('utf-8')
        
        try:
            import zlib
            return zlib.decompress(data).decode('utf-8')
        except:
            # ì••ì¶•ë˜ì§€ ì•Šì€ ë°ì´í„°ë¡œ ê°„ì£¼
            return data.decode('utf-8')
    
    async def get(self, question: str, category: Optional[str] = None, 
                  section: Optional[str] = None) -> Optional[Tuple[str, bool]]:
        """
        ìºì‹œì—ì„œ ì‘ë‹µì„ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Returns:
            Optional[Tuple[str, bool]]: (ì‘ë‹µ, is_fallback) ë˜ëŠ” None
        """
        start_time = time.time()
        self.stats['total_requests'] += 1
        
        try:
            # L1 ìºì‹œ í™•ì¸ (ë¡œì»¬ ë©”ëª¨ë¦¬)
            l1_result = self.l1_cache.get(question, category, section)
            if l1_result:
                self.stats['l1_hits'] += 1
                return l1_result
            
            # L2 ìºì‹œ í™•ì¸ (Redis)
            if await self._check_redis_health():
                cache_key = self._generate_cache_key(question, category, section)
                
                try:
                    redis_data = await asyncio.wait_for(
                        self.redis_client.get(cache_key),
                        timeout=2.0
                    )
                    
                    if redis_data:
                        # Redisì—ì„œ ì°¾ì€ ë°ì´í„°ë¥¼ L1ì—ë„ ì €ì¥
                        decompressed = self._decompress_data(redis_data)
                        cached_data = json.loads(decompressed)
                        
                        answer = cached_data['answer']
                        is_fallback = cached_data['is_fallback']
                        
                        # L1 ìºì‹œì— ì¶”ê°€ (ë¹ ë¥¸ ì ‘ê·¼ì„ ìœ„í•´)
                        self.l1_cache.set(question, answer, is_fallback, category, section)
                        
                        self.stats['l2_hits'] += 1
                        return (answer, is_fallback)
                
                except asyncio.TimeoutError:
                    print("âš ï¸ Redis ì¡°íšŒ íƒ€ì„ì•„ì›ƒ")
                    self.stats['errors'] += 1
                except Exception as e:
                    print(f"âš ï¸ Redis ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
                    self.stats['errors'] += 1
            
            # ìºì‹œ ë¯¸ìŠ¤
            self.stats['misses'] += 1
            return None
            
        finally:
            # ì‘ë‹µ ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸
            response_time = time.time() - start_time
            self._update_avg_response_time(response_time)
    
    async def set(self, question: str, answer: str, is_fallback: bool,
                  category: Optional[str] = None, section: Optional[str] = None) -> bool:
        """
        ìºì‹œì— ì‘ë‹µì„ ì €ì¥í•©ë‹ˆë‹¤.
        
        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # L1 ìºì‹œì— ì €ì¥
            self.l1_cache.set(question, answer, is_fallback, category, section)
            
            # L2 ìºì‹œì— ì €ì¥ (Redis)
            if await self._check_redis_health():
                cache_key = self._generate_cache_key(question, category, section)
                cache_data = {
                    'answer': answer,
                    'is_fallback': is_fallback,
                    'timestamp': datetime.now().isoformat(),
                    'category': category,
                    'section': section
                }
                
                try:
                    compressed_data = self._compress_data(json.dumps(cache_data))
                    ttl_seconds = self.config.l2_ttl_hours * 3600
                    
                    await asyncio.wait_for(
                        self.redis_client.setex(cache_key, ttl_seconds, compressed_data),
                        timeout=2.0
                    )
                    return True
                    
                except asyncio.TimeoutError:
                    print("âš ï¸ Redis ì €ì¥ íƒ€ì„ì•„ì›ƒ")
                    self.stats['errors'] += 1
                except Exception as e:
                    print(f"âš ï¸ Redis ì €ì¥ ì˜¤ë¥˜: {str(e)}")
                    self.stats['errors'] += 1
            
            return True  # L1 ì €ì¥ì€ ì„±ê³µ
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False
    
    async def clear_by_pattern(self, pattern: str) -> int:
        """íŒ¨í„´ì— ë§ëŠ” ìºì‹œ í‚¤ë“¤ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
        if not await self._check_redis_health():
            return 0
        
        try:
            keys = await self.redis_client.keys(f"chat_cache:*{pattern}*")
            if keys:
                deleted = await self.redis_client.delete(*keys)
                print(f"ğŸ—‘ï¸ Redisì—ì„œ {deleted}ê°œ í‚¤ ì‚­ì œ (íŒ¨í„´: {pattern})")
                return deleted
        except Exception as e:
            print(f"âš ï¸ Redis íŒ¨í„´ ì‚­ì œ ì˜¤ë¥˜: {str(e)}")
        
        return 0
    
    async def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        l1_stats = self.l1_cache.get_stats()
        
        redis_info = {}
        if await self._check_redis_health():
            try:
                redis_info = await self.redis_client.info('memory')
                redis_keys = await self.redis_client.dbsize()
                redis_info['total_keys'] = redis_keys
            except Exception as e:
                redis_info = {'error': str(e)}
        
        return {
            'l1_cache': l1_stats,
            'l2_cache': {
                'healthy': self.redis_healthy,
                'info': redis_info
            },
            'combined_stats': self.stats,
            'config': {
                'l1_max_size': self.config.l1_max_size,
                'l2_ttl_hours': self.config.l2_ttl_hours,
                'compression_enabled': self.config.compression_enabled
            }
        }
    
    def _update_avg_response_time(self, response_time: float):
        """í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        current_avg = self.stats['avg_response_time']
        total_requests = self.stats['total_requests']
        
        # ì´ë™ í‰ê·  ê³„ì‚°
        if total_requests == 1:
            self.stats['avg_response_time'] = response_time
        else:
            alpha = 2.0 / (total_requests + 1)  # ì§€ìˆ˜ ì´ë™ í‰ê· 
            self.stats['avg_response_time'] = alpha * response_time + (1 - alpha) * current_avg
    
    async def close(self):
        """ì—°ê²°ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
        if self.redis_client:
            try:
                await self.redis_client.close()
            except:
                pass
        
        if self.redis_pool:
            try:
                await self.redis_pool.disconnect()
            except:
                pass

# ì „ì—­ ë¶„ì‚° ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
_distributed_cache: Optional[DistributedCacheManager] = None
_cache_lock = threading.Lock()

async def get_distributed_cache() -> DistributedCacheManager:
    """ì „ì—­ ë¶„ì‚° ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _distributed_cache
    
    if _distributed_cache is None:
        with _cache_lock:
            if _distributed_cache is None:
                config = CacheConfig(
                    redis_url=os.getenv('REDIS_URL', 'redis://localhost:6379'),
                    redis_password=os.getenv('REDIS_PASSWORD'),
                    redis_db=int(os.getenv('REDIS_DB', '0')),
                    l1_max_size=int(os.getenv('CACHE_L1_SIZE', '100')),
                    l2_ttl_hours=int(os.getenv('CACHE_L2_TTL_HOURS', '24'))
                )
                
                _distributed_cache = DistributedCacheManager(config)
                await _distributed_cache.initialize()
    
    return _distributed_cache

# í¸ì˜ í•¨ìˆ˜ë“¤
async def get_cached_response(question: str, category: Optional[str] = None, 
                            section: Optional[str] = None) -> Optional[Tuple[str, bool]]:
    """ìºì‹œëœ ì‘ë‹µì„ ì¡°íšŒí•˜ëŠ” í¸ì˜ í•¨ìˆ˜"""
    cache = await get_distributed_cache()
    return await cache.get(question, category, section)

async def cache_response(question: str, answer: str, is_fallback: bool,
                        category: Optional[str] = None, section: Optional[str] = None) -> bool:
    """ì‘ë‹µì„ ìºì‹œì— ì €ì¥í•˜ëŠ” í¸ì˜ í•¨ìˆ˜"""
    cache = await get_distributed_cache()
    return await cache.set(question, answer, is_fallback, category, section)

async def invalidate_cache_pattern(pattern: str) -> int:
    """íŒ¨í„´ì— ë§ëŠ” ìºì‹œë¥¼ ë¬´íš¨í™”í•˜ëŠ” í¸ì˜ í•¨ìˆ˜"""
    cache = await get_distributed_cache()
    return await cache.clear_by_pattern(pattern)

# ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
@asynccontextmanager
async def distributed_cache_context():
    """ë¶„ì‚° ìºì‹œ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    cache = await get_distributed_cache()
    try:
        yield cache
    finally:
        await cache.close() 